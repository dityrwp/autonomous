# Training Configuration

# Basic Training Settings
train:
  epochs: 54 # Return to original value for proper convergence
  batch_size: 4  # Increase batch size if memory allows
  num_workers: 8  # Keep the increased worker count
  pin_memory: true
  mixed_precision: true  # Keep mixed precision for memory efficiency
  sync_bn: true  # Use SyncBatchNorm for multi-GPU
  deterministic: false  # Set to false for better performance
  seed: 42

# Dataset Configuration
dataset:
  # Paths to dataset
  dataroot: "/home/mevi/Documents/bev/nuscenes_full"  # Updated path to NuScenes dataset
  bev_labels_dir: "/home/mevi/Documents/bev/bev_labels"  # Updated path to precomputed BEV labels
  version: "v1.0-trainval"  # NuScenes version

# Class Colors for Visualization (RGB format)
class_colors:
  - [252, 252, 252]  # Background (near white)
  - [166, 206, 227]  # Drivable Area (light blue)
  - [202, 178, 214]  # Road Divider (grayish purple)
  - [106, 61, 154]   # Lane Divider (dark purple)
  - [224, 74, 76]    # Walkway (red)
  - [251, 154, 153]  # Pedestrian Crossing (light pink)

# Optimization
optimizer:
  name: "AdamW"
  lr_camera: 5.0e-5  # Reduced learning rate for stability
  lr_lidar: 5.0e-5   # Reduced learning rate for stability
  lr_fusion: 5.0e-5  # Reduced learning rate for stability
  lr_head: 5.0e-5    # Reduced learning rate for stability
  weight_decay: 0.01
  beta1: 0.9
  beta2: 0.999
  eps: 1.0e-8
  grad_clip: 1.0  # Add gradient clipping to prevent unstable gradients

# Learning Rate Scheduler
scheduler:
  name: "CosineAnnealingLR"
  T_max: 50  # Match with epochs
  eta_min: 1.0e-6
  warmup_epochs: 3  # Reduced for shorter training
  warmup_ratio: 0.1

# Loss Configuration
loss:
  focal_loss:
    gamma: 2.0    # Reduced from 2.0 for more stability
    alpha: 0.25
  # Modified class weights based on observed class imbalance
  # Significantly increase weights for lane and road dividers to address the imbalance
  class_weights: [0.75, 0.5, 5.0, 5.0, 2.0, 1.0]  # Increased weights for underrepresented classes
  loss_weights:
    segmentation: 1.0
  # New parameters for numerical stability  
  label_smoothing: 0.05
  gradient_clip: 1.0
  use_dynamic_weighting: false
  # Dice loss parameters
  use_dice_loss: true
  dice_weight: 0.5  # Equal weight for dice and focal loss
  dice_smooth: 1.0  # Smoothing factor for dice loss

# Validation
val:
  interval: 1  # Validate every epoch
  batch_size: 4  # Increased 
  save_predictions: true
  visualization_threshold: 0.5

# Checkpointing
checkpoint:
  save_dir: "checkpoints"
  save_interval: 2  # Save every 5 epochs
  save_best: true
  save_last: true
  resume: true  # Changed to false since we're starting fresh training with new data
  resume_path: "outputs/checkpoints/checkpoint_epoch_50.pth"

# Logging
logging:
  log_dir: "logs"
  log_interval: 20  # Log more frequently
  metrics:
    - "loss"
    - "mean_iou"
    - "class_iou"
    - "precision"
    - "recall"
  visualization:
    save_dir: "visualizations"
    max_images: 8  # Reduced from 16 to save disk space and processing time

# Hardware
hardware:
  gpu_ids: [0]  # List of GPU ids to use
  dist_backend: "nccl"
  dist_url: "tcp://localhost:12345"


# Debug
debug:
  enabled: false
  subset_size: 9667  # Number of samples to use in debug mode
  profile: false  # Enable profiling
  check_nan: true  # Check for NaN values
