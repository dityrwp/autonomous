# Training Configuration

# Basic Training Settings
train:
  epochs: 50  # Return to original value for proper convergence
  batch_size: 4  # Increase batch size if memory allows
  num_workers: 8  # Keep the increased worker count
  pin_memory: true
  mixed_precision: true  # Keep mixed precision for memory efficiency
  sync_bn: true  # Use SyncBatchNorm for multi-GPU
  deterministic: false  # Set to false for better performance
  seed: 42

# Dataset Configuration
dataset:
  # Paths to dataset
  dataroot: "/home/mevi/Documents/bev/nuscenes_full"  # Updated path to NuScenes dataset
  bev_labels_dir: "/home/mevi/Documents/bev/bev_labels"  # Updated path to precomputed BEV labels
  version: "v1.0-trainval"  # NuScenes version

# Optimization
optimizer:
  name: "AdamW"
  lr_camera: 5.0e-5  # Reduced learning rate for stability
  lr_lidar: 5.0e-5   # Reduced learning rate for stability
  lr_fusion: 5.0e-5  # Reduced learning rate for stability
  lr_head: 5.0e-5    # Reduced learning rate for stability
  weight_decay: 0.01
  beta1: 0.9
  beta2: 0.999
  eps: 1.0e-8
  grad_clip: 1.0  # Add gradient clipping to prevent unstable gradients

# Learning Rate Scheduler
scheduler:
  name: "CosineAnnealingLR"
  T_max: 50  # Match with epochs
  eta_min: 1.0e-6
  warmup_epochs: 3  # Reduced for shorter training
  warmup_ratio: 0.1

# Loss Configuration
loss:
  focal_loss:
    gamma: 1.5    # Reduced from 2.0 for more stability
    alpha: 0.25
  # Modified class weights based on observed class imbalance
  # Significantly increase weights for lane and road dividers to address the imbalance
  class_weights: [0.75, 0.5, 4.0, 4.0, 1.5, 0.75]  # Increased weights for underrepresented classes
  loss_weights:
    segmentation: 1.0
  # New parameters for numerical stability  
  label_smoothing: 0.05
  gradient_clip: 1.0
  use_dynamic_weighting: false
  # Dice loss parameters
  use_dice_loss: true
  dice_weight: 0.5  # Equal weight for dice and focal loss
  dice_smooth: 1.0  # Smoothing factor for dice loss

# Validation
val:
  interval: 1  # Validate every epoch
  batch_size: 4  # Increased 
  save_predictions: true
  visualization_threshold: 0.5

# Checkpointing
checkpoint:
  save_dir: "checkpoints"
  save_interval: 5  # Save every 5 epochs
  save_best: true
  save_last: true
  resume: false  # Changed to false since we're starting fresh training with new data
  resume_path: "outputs/checkpoints/last_model.pth"

# Logging
logging:
  log_dir: "logs"
  log_interval: 20  # Log more frequently
  metrics:
    - "loss"
    - "mean_iou"
    - "class_iou"
    - "precision"
    - "recall"
  visualization:
    save_dir: "visualizations"
    max_images: 8  # Reduced from 16 to save disk space and processing time

# Hardware
hardware:
  gpu_ids: [0]  # List of GPU ids to use
  dist_backend: "nccl"
  dist_url: "tcp://localhost:12345"

# Data Augmentation
augmentation:
  enabled: true
  random_flip: true  # Only horizontal flips will be enabled in code
  random_rotate: true
  rotate_range: [-3.0, 3.0]  # Reduced from [-10, 10] to prevent unrealistic road alignments
  scale_range: [0.95, 1.05]
  translation_std: [0.2, 0.2, 0.2]
  cutout_prob: 0.3  # Reduced from default 0.5 
  cutout_max_size: [20, 20]  # Reduced from default to be less disruptive
  mixup_prob: 0.0  # Disabled mixup completely as it creates unrealistic scenes

# Debug
debug:
  enabled: false
  subset_size: 8530  # Number of samples to use in debug mode
  profile: false  # Enable profiling
  check_nan: true  # Check for NaN values
