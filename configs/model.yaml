# Model Configuration

# Backbone Configurations
camera_backbone:
  type: efficientnet
  pretrained: true
  channels:
    stage3: 64
    stage4: 128
    stage5: 256

lidar_backbone:
  type: pointpillars
  voxel_size: [0.8, 0.8, 0.8]
  point_cloud_range: [-51.2, -51.2, -5, 51.2, 51.2, 3]
  max_num_points: 32
  max_voxels: 20000

# Fusion Configuration
fusion:
  type: cross_attention
  use_multi_scale: true  # Enable multi-scale fusion
  output_channels: 128
  spatial_size: [128, 128]
  chunk_size: 1024
  use_reentrant: true
  stage_channels:
    stage1: 64
    stage2: 128
    stage3: 256

# Segmentation Head Configuration
segmentation_head:
  in_channels: 128
  hidden_channels: 128
  num_classes: 6  # NuScenes BEV classes: background, drivable_area, lane_divider, road_divider, ped_crossing, walkway
  use_focal_loss: true
  dropout: 0.1
  focal_gamma: 1.5
  learnable_alpha: false
  initial_alpha: 0.25
  use_dice_loss: true
  dice_weight: 0.5
  dice_smooth: 1.0

# Data Configuration
input_config:
  image_size: [640, 480]
  num_cameras: 1  # Using front camera only
  max_points_per_frame: 300000

# Class Mapping
class_map:
  background: 0
  drivable_area: 1
  lane_divider: 2
  road_divider: 3
  ped_crossing: 4
  walkway: 5

# Augmentation Configuration
augmentation:
  random_flip: true
  random_rotate:
    prob: 0.5
    degrees: 10
  random_scale:
    prob: 0.5
    scale_range: [0.95, 1.05]
  random_translate:
    prob: 0.5
    translate_range: [0.1, 0.1]
  random_brightness:
    prob: 0.5
    brightness_factor: 0.2
  random_contrast:
    prob: 0.5
    contrast_range: [0.8, 1.2]
  random_cutout:
    prob: 0.5
    num_cutouts: 5
    cutout_size: [0.02, 0.1]
