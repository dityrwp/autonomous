#!/usr/bin/env python
import os
import sys
import numpy as np
import torch
from torch.utils.data import DataLoader
import logging
import argparse
from tqdm import tqdm
import matplotlib.pyplot as plt
import json
from pathlib import Path

# Add parent directory to path to import project modules
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from datasets.nuscenes_data import NuScenesFilteredDataset, NuScenesBEVLabelDataset

def parse_args():
    parser = argparse.ArgumentParser(description='Precompute BEV labels from NuScenes dataset')
    parser.add_argument('--dataroot', type=str, required=True, help='Path to NuScenes dataset')
    parser.add_argument('--version', type=str, default='v1.0-trainval', help='NuScenes version')
    parser.add_argument('--splits', nargs='+', default=['train', 'val'], help='Dataset splits to process')
    parser.add_argument('--grid-size', type=int, default=128, help='Grid size for BEV labels')
    parser.add_argument('--resolution', type=float, default=0.2, help='Resolution in meters per pixel')
    parser.add_argument('--output-dir', type=str, default='data/bev_labels', help='Output directory for BEV labels')
    parser.add_argument('--format', type=str, choices=['npy', 'png'], default='npy', 
                        help='Output format (npy for numpy array, png for image)')
    return parser.parse_args()

def save_label(label, output_path, format='npy', metadata=None):
    """Save label in specified format with optional metadata."""
    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    
    if format == 'npy':
        np.save(output_path + '.npy', label)
    elif format == 'png':
        # Save as PNG (useful for visualization)
        # Scale values to 0-255 for better visibility
        plt.imsave(output_path + '.png', label, cmap='tab10', vmin=0, vmax=max(6, label.max()))
    
    # Save metadata if provided
    if metadata:
        with open(output_path + '.json', 'w') as f:
            json.dump(metadata, f)

def precompute_bev_labels(args):
    """Precompute BEV labels for all samples in the dataset."""
    logging.info(f"Precomputing BEV labels for {args.version} dataset")
    
    # Process each split
    for split in args.splits:
        logging.info(f"Processing {split} split...")
        
        # Create output directory for this split
        split_output_dir = os.path.join(args.output_dir, split)
        os.makedirs(split_output_dir, exist_ok=True)
        
        # Initialize datasets
        filtered_dataset = NuScenesFilteredDataset(
            dataroot=args.dataroot,
            version=args.version,
            split=split
        )
        
        bev_dataset = NuScenesBEVLabelDataset(
            filtered_dataset=filtered_dataset,
            grid_size=args.grid_size,
            resolution=args.resolution
        )
        
        # Create a mapping file to track sample tokens and file paths
        mapping_file = os.path.join(split_output_dir, 'sample_mapping.json')
        mapping = {
            'version': args.version,
            'split': split,
            'grid_size': args.grid_size,
            'resolution': args.resolution,
            'samples': []
        }
        
        # Process each sample
        for idx in tqdm(range(len(bev_dataset)), desc=f"Generating BEV labels for {split}"):
            # Get sample data
            sample_data = bev_dataset[idx]
            sample_token = sample_data['sample_token']
            
            # Get scene information
            sample = bev_dataset.nusc.get('sample', sample_token)
            scene = bev_dataset.nusc.get('scene', sample['scene_token'])
            scene_name = scene['name']
            scene_token = scene['token']
            
            # Create output structure: split/scene_token/sample_token.npy
            scene_dir = os.path.join(split_output_dir, scene_token)
            os.makedirs(scene_dir, exist_ok=True)
            
            # Get BEV label (already generated by dataset)
            bev_label = sample_data['bev_label'].numpy()
            
            # Save label
            output_path = os.path.join(scene_dir, sample_token)
            save_label(
                bev_label, 
                output_path, 
                format=args.format,
                metadata={
                    'scene_name': scene_name,
                    'scene_token': scene_token,
                    'sample_token': sample_token,
                    'timestamp': sample['timestamp'],
                    'class_map': bev_dataset.class_map,
                    'grid_size': args.grid_size,
                    'resolution': args.resolution
                }
            )
            
            # Get the original data paths for inputs
            original_sample = filtered_dataset[idx]
            
            # Add to mapping
            mapping['samples'].append({
                'sample_token': sample_token,
                'scene_token': scene_token,
                'scene_name': scene_name,
                'bev_label_path': os.path.relpath(output_path + '.' + args.format, split_output_dir),
                'lidar_path': os.path.relpath(original_sample['lidar'], args.dataroot),
                'image_path': os.path.relpath(original_sample['image'], args.dataroot),
                'timestamp': sample['timestamp']
            })
        
        # Save mapping file
        with open(mapping_file, 'w') as f:
            json.dump(mapping, f, indent=2)
        
        logging.info(f"Processed {len(mapping['samples'])} samples for {split} split")
        logging.info(f"Mapping saved to {mapping_file}")

def main():
    # Configure logging
    logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')
    
    # Parse arguments
    args = parse_args()
    
    # Create output directory
    os.makedirs(args.output_dir, exist_ok=True)
    
    # Run precomputation
    precompute_bev_labels(args)
    
    logging.info("BEV label precomputation completed!")

if __name__ == "__main__":
    main() 